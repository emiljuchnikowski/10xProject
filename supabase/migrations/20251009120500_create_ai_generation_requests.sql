-- migration: create ai_generation_requests table
-- purpose: track ai flashcard generation requests with token usage and status
-- affected tables: ai_generation_requests
-- special considerations:
--   - input_text must be between 1000 and 10000 characters
--   - tracks token usage (prompt_tokens, completion_tokens) for cost monitoring
--   - status field tracks request lifecycle (pending, succeeded, failed)
--   - cascade delete when user is deleted

-- create ai_generation_requests table
create table ai_generation_requests (
  id integer primary key generated by default as identity,
  user_id uuid not null references auth.users(id) on delete cascade,
  input_text text not null check (char_length(input_text) between 1000 and 10000),
  model text,
  suggestion_count integer,
  prompt_tokens integer,
  completion_tokens integer,
  status text not null default 'pending' check (status in ('pending', 'succeeded', 'failed')),
  error text,
  created_at timestamptz not null default now()
);

-- create index on user_id for faster lookups by user
create index ai_generation_requests_user_id_idx on ai_generation_requests(user_id);

-- create index on status for filtering by request status
create index ai_generation_requests_status_idx on ai_generation_requests(status);

-- create index on created_at for chronological queries (most recent first)
create index ai_generation_requests_created_at_idx on ai_generation_requests(created_at desc);
